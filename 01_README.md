# AnÃ¡lisis de Clustering de PaÃ­ses - Dataset QoG 2019

## ğŸ“‹ INFORMACIÃ“N DEL AUTOR

| Campo | Dato                                                            |
|-------|-----------------------------------------------------------------|
| **Nombre** | Camilo GarcÃ­a Rey                                               |
| **Fecha** | 10 de febrero de 2026                                           |
| **Asignatura** | Infraestructura de Procesamiento de Datos                       |
| **Proyecto** | Bloque A (30%) + Bloque B (25%) + Bloque C (25%) + Bloque D (20%) |

## ğŸ¯ PREGUNTA DE INVESTIGACIÃ“N

**Â¿CÃ³mo se agrupan los paÃ­ses globalmente al cruzar desarrollo econÃ³mico, calidad democrÃ¡tica y corrupciÃ³n? Â¿Existen perfiles hÃ­bridos (ej. paÃ­ses ricos autocrÃ¡ticos o democracias pobres)?**

### HipÃ³tesis inicial:
- DeberÃ­an formarse clusters que agrupen paÃ­ses con caracterÃ­sticas similares
- Posibles perfiles hÃ­bridos: paÃ­ses con alto PIB pero baja democracia (ej. Singapur, Kuwait)
- PaÃ­ses con alta democracia pero bajo PIB (ej. algunos paÃ­ses de Europa del Este)

## ğŸŒ CONFIGURACIÃ“N DEL DATASET

### AÃ±o de estudio: **2019**

### PaÃ­ses analizados (20 paÃ­ses de 4 continentes):

| Continente | PaÃ­ses |
|------------|--------|
| **AmÃ©rica** | Canada, Uruguay, Haiti, Chile, Cuba |
| **Europa** | Norway, Poland, Moldova, Netherlands, Belarus |
| **Asia** | Singapore, Kuwait, Japan, Viet Nam, India |
| **Ãfrica** | Botswana, Rwanda, South Africa, Ethiopia, Mauritius |

### Variables seleccionadas:

| Variable | DescripciÃ³n |
|----------|-------------|
| `vdem_polyarchy` | Ãndice de democracia electoral (0-1, mÃ¡s alto = mÃ¡s democrÃ¡tico) |
| `ti_cpi` | Ãndice de percepciÃ³n de corrupciÃ³n (0-100, mÃ¡s alto = menos corrupciÃ³n) |
| `wdi_expedu` | Gasto en educaciÃ³n como % del PIB |
| `wdi_gdpcapcon2015` | PIB per cÃ¡pita (dÃ³lares constantes 2015) |
| `vdem_libdem` | Ãndice de democracia liberal (para cÃ¡lculo de brecha) |

## ğŸ—ï¸ INFRAESTRUCTURA TECNOLÃ“GICA

### Arquitectura del sistema:
![img_8.png](img_8.png)


### Componentes:

| Componente | EspecificaciÃ³n |
|------------|----------------|
| **Sistema Operativo** | Windows (con Docker Desktop) |
| **IDE** | PyCharm con Python 3.14 (local) / Python 3.8.10 (contenedor) |
| **OrquestaciÃ³n** | Docker Compose |
| **Procesamiento** | Apache Spark 3.5.4 (modo cluster) |
| **Base de datos** | PostgreSQL 16 Alpine |
| **AnÃ¡lisis** | scikit-learn (K-Means, PCA) |

## ğŸ“Š METODOLOGÃA DE ANÃLISIS

### Fase 1: Infraestructura (Bloque A)
1. ConfiguraciÃ³n de docker-compose.yml con 3 servicios
2. Named volumes para persistencia de datos PostgreSQL
3. Health checks para verificar disponibilidad
4. InstalaciÃ³n automÃ¡tica de dependencias Python en contenedores Spark

### Fase 2: ETL con PySpark (Bloque B)
1. Carga de dataset QoG desde CSV
2. Filtrado de paÃ­ses especÃ­ficos para aÃ±o 2019
3. IngenierÃ­a de variables:
   - `Liberal_gap = vdem_polyarchy - vdem_libdem`
   - `wdi_gdpcapcon2015_log = log(PIB + 1)`
4. Almacenamiento en PostgreSQL (tabla `qog_processed`)

### Fase 3: AnÃ¡lisis de Clustering (Bloque C)
1. NormalizaciÃ³n con `StandardScaler`
2. OptimizaciÃ³n de K mediante mÃ©todo del codo
3. AplicaciÃ³n de K-Means con K Ã³ptimo
4. ReducciÃ³n dimensional con PCA a 2 componentes
5. VisualizaciÃ³n 2D de clusters con etiquetas de paÃ­ses
6. AnÃ¡lisis de perfiles por cluster

## ğŸ”§ DESAFÃOS TÃ‰CNICOS ENCONTRADOS

### Problemas resueltos durante el desarrollo:

| Problema | SoluciÃ³n |
|----------|----------|
| Permisos PostgreSQL en Windows | Uso de named volumes en lugar de bind mounts |
| InstalaciÃ³n de dependencias en Spark | EjecuciÃ³n como root temporal + `exec su spark` |
| Error de sintaxis en pipeline.py | CorrecciÃ³n de comillas faltantes y barras invertidas |
| ConexiÃ³n PostgreSQL desde Spark | Cambio de host: `localhost` â†’ `postgres` |
| Versiones incompatibles Python | Ajuste de requirements para Python 3.8 |

## ğŸ“ˆ RESULTADOS ESPERADOS

El pipeline genera:

1. **MÃ©todo del codo** (`elbow_method.png`): GrÃ¡fico para determinar K Ã³ptimo
2. **VisualizaciÃ³n PCA** (`clustering_pca.png`): Clusters en espacio 2D
3. **Tabla PostgreSQL** `clustering_results`: Resultados completos
4. **EstadÃ­sticas por cluster** (`cluster_statistics.csv`): Promedios por grupo

## ğŸš€ CÃ“MO EJECUTAR EL PROYECTO

### Prerrequisitos:
- Docker Desktop instalado y funcionando
- Archivo `qog.csv` en carpeta `data/`
- Git (opcional)

### Pasos de ejecuciÃ³n:

```bash
# 1. Clonar/descargar el proyecto
cd D:\db_docker

# 2. Levantar infraestructura
docker-compose up -d

# 3. Esperar 30 segundos para inicializaciÃ³n
timeout 30

# 4. Verificar estado
docker-compose ps

# 5. Ejecutar pipeline
docker exec spark-master /opt/spark/bin/spark-submit \
  --master spark://spark-master:7077 \
  /opt/spark-apps/pipeline.py

# 6. Copiar resultados
docker cp spark-master:/opt/spark-apps/elbow_method.png .
docker cp spark-master:/opt/spark-apps/clustering_pca.png .

D:\bd_docker\
â”œâ”€â”€ data\
â”‚   â””â”€â”€ qog.csv                    # Dataset original
â”œâ”€â”€ spark-apps\
â”‚   â””â”€â”€ pipeline.py                 # Script principal ETL + clustering
â”œâ”€â”€ resultados_finales\             # GrÃ¡ficos y CSV generados
â”‚   â”œâ”€â”€ elbow_method.png
â”‚   â”œâ”€â”€ clustering_pca.png
â”‚   â”œâ”€â”€ clustering_results.csv
â”‚   â””â”€â”€ cluster_statistics.csv
â”œâ”€â”€ docker-compose.yml              # OrquestaciÃ³n de servicios
â”œâ”€â”€ requirements.txt                # Dependencias Python
â”œâ”€â”€ .gitignore                      # Archivos ignorados por git
â”œâ”€â”€ 01_README.md                    # Este archivo
â”œâ”€â”€ 02_INFRAESTRUCTURA.md           # DocumentaciÃ³n Docker
â”œâ”€â”€ 03_RESULTADOS.md                # AnÃ¡lisis y grÃ¡ficos
â”œâ”€â”€ 04_REFLEXION_IA.md              # Momentos clave y prompts
â”œâ”€â”€ 05_RESPUESTAS.md                # Preguntas de comprensiÃ³n
â””â”€â”€ PROMPTS.md                      # Historial de prompts IA

ğŸ“Š TECNOLOGÃAS UTILIZADAS
TecnologÃ­a	VersiÃ³n	PropÃ³sito
Docker Desktop	20.10+	Contenedores
Docker Compose	3.8	OrquestaciÃ³n
Apache Spark	3.5.4	Procesamiento distribuido
PostgreSQL	16 Alpine	Almacenamiento
Python	3.8 (contenedor)	Lenguaje principal
PySpark	3.5.4	API Spark para Python
pandas	1.5.3	ManipulaciÃ³n de datos
scikit-learn	1.3.2	Clustering y PCA
matplotlib	3.7.4	VisualizaciÃ³n
seaborn	0.13.0	Estilo de grÃ¡ficos


ğŸ‘¨â€ğŸ’» NOTAS DEL DESARROLLADOR
Este proyecto fue desarrollado en Windows con Docker Desktop, enfrentando desafÃ­os tÃ­picos de permisos y compatibilidad entre sistemas. La soluciÃ³n implementada utiliza named volumes para persistencia y ejecuciÃ³n como root temporal para instalaciÃ³n de dependencias.

Principales aprendizajes:

Los bind mounts en Windows tienen limitaciones de permisos

Spark en contenedores requiere manejo cuidadoso de usuarios

La comunicaciÃ³n entre servicios Docker usa nombres de servicio, no localhost

Las versiones de Python en contenedores oficiales son fijas

ğŸ“§ CONTACTO
Para cualquier consulta sobre este proyecto:

Nombre: Camilo GarcÃ­a Rey

Email: camilogrey@gmail.com

GitHub: https://github.com/camilogrey