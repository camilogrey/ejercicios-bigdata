# üèóÔ∏è Infraestructura del Laboratorio

> **"Evita que Big Data colapse tu disco principal"**

Para realizar este curso, hemos dise√±ado una arquitectura h√≠brida que combina la facilidad de uso de Windows con la potencia de servidores Linux aislados en Docker.

Esta gu√≠a te explica **qu√© est√° pasando "bajo el cap√≥"** cuando ejecutas el script de instalaci√≥n.

---

## üß© Arquitectura H√≠brida

Nuestro entorno utiliza tres capas:

1.  **Capa de Usuario (T√∫):** Escribes c√≥digo Python en PyCharm/VSCode.
2.  **Capa de C√≥mputo (Docker):** Servicios pesados (Spark, Postgres) corren aislados.
3.  **Capa de Datos (Storage):** Los archivos masivos se guardan en un disco dedicado.

```mermaid
graph TD
    subgraph "Tu Ordenador"
        IDE[PyCharm / VSCode] -->|Ejecuta| PY[Scripts Python]
        PY -->|Conecta puerto 5432| PG[(PostgreSQL)]
        PY -->|Conecta puerto 7077| SPARK[Spark Cluster]
    end
    
    subgraph "Docker (Contenedores)"
        PG
        SPARK
        ADMIN[pgAdmin4]
    end
    
    subgraph "Almacenamiento F√≠sico"
        SSD[SSD Externo / Partici√≥n Datos]
        HDD[Disco Sistema C:]
    end
    
    PG -->|Guarda| SSD
    SPARK -->|Lee| SSD
    PY -.->|Junction Link| SSD
```

---

## üíæ El Dilema del Almacenamiento (HDD vs SSD)

En Proyectos de Datos, el **I/O (Velocidad de disco)** es cr√≠tico.

### üöÄ Opci√≥n A: SSD Externo (Modo PRO)
Si tienes el laboratorio configurado en un SSD externo (`E:\BIGDATA_LAB_STORAGE`):
1.  **Velocidad:** Docker tiene un carril exclusivo para leer/escribir datos.
2.  **Seguridad:** Si descargas un dataset de 50GB, tu Windows no se queda sin espacio.
3.  **El "T√∫nel M√°gico" (Junction):** Windows crea un enlace simb√≥lico. T√∫ ves la carpeta `datos/` en tu proyecto, pero f√≠sicamente los bytes est√°n en el SSD externo.

### üê¢ Opci√≥n B: Disco Local
Si usas tu disco principal (`C:`):
- El sistema funcionar√° igual, pero debes vigilar el espacio libre.
- Docker y Windows competir√°n por el uso del disco (performance menor).

---

## üê≥ Servicios Docker (El "Stack")

El script `setup_cluster.ps1` levanta estos servicios autom√°ticamente:

### 1. PostgreSQL (El Data Warehouse)
*   **Por qu√© SQL:** Aunque procesamos con Spark/Dask, los datos finales "de valor" deben residir en una base de datos estructurada para ser consumidos por Dashboards o Analistas.
*   **Por qu√© no Mongo/Cassandra:** Para este nivel de datos (Gigabytes estructurados), PostgreSQL es m√°s eficiente en recursos locales y es el est√°ndar de oro para la capa de "Serving".
*   **Acceso:** `localhost:5432`

### 2. Apache Spark (El Motor de Proceso)
*   **Master + Worker:** Simulamos un cluster real. El "Master" reparte tareas y el "Worker" las ejecuta.
*   **Acceso:** `localhost:8081` (Dashboard)

### 3. pgAdmin 4 (La Interfaz)
*   Una web para gestionar tu base de datos SQL sin comandos.
*   **Acceso:** `http://localhost:8080`

---

## üöë Docker Rescue

¬øTe ha pasado que Docker "no arranca"? El script de setup incluye un m√≥dulo de rescate:
1.  Verifica si el servicio de Windows `com.docker.service` est√° corriendo.
2.  Si est√° detenido, intenta reiniciarlo con permisos de administrador.
3.  Espera a que el motor est√© listo antes de intentar levantar los contenedores.

---

## üõ†Ô∏è C√≥mo Iniciar

Para levantar el stack de Docker, abre PowerShell como Administrador y ejecuta:

```powershell
# Navegar a la carpeta del proyecto
cd "C:\Users\TU_USUARIO\Documents\ejercicios_bigdata"

# Levantar los servicios
docker-compose up -d

# Verificar que est√°n corriendo
docker ps
```

**Servicios disponibles despu√©s de iniciar:**
- PostgreSQL: `localhost:5432`
- Spark Master UI: `localhost:8081`
- pgAdmin: `localhost:8080`
